# CONTRASTIVE LABEL DISAMBIGUATION FOR PARTIAL LABEL LEARNING

## Abstract

部分标签学习（PLL）是一个重要的问题，它允许每个训练样本用一个粗略的候选集进行标记，这非常适合许多具有标签模糊性的现实世界数据注释场景。尽管有希望，但 PLL 的性能往往落后于受监督的对手。在这项工作中，我们通过在一个连贯的框架中解决 PLL 中的两个关键研究挑战——表示学习和标签消歧——来弥合差距。具体来说，我们提出的框架 PiCO 由一个对比学习模块和一个新颖的基于类原型的标签消歧算法组成。 PiCO 为来自同一类的示例生成紧密对齐的表示，并促进标签消歧。从理论上讲，我们证明这两个组件可以互相促进，并且可以从期望最大化（EM）算法的角度得到严格证明。大量实验表明，PiCO 在 PLL 中显着优于当前最先进的方法，甚至可以达到与完全监督学习相当的结果。

## 1 Introduction

现代深度神经网络的训练通常需要大量的标记数据，这给数据收集带来了巨大的障碍。在一个特殊的挑战中，现实世界中的数据注释自然会受到固有的标签模糊性和噪声的影响。例如，如图 1 所示，人类注释者可能很难从西伯利亚雪橇犬中识别出阿拉斯加雪橇犬。标签模糊性问题很普遍，但在许多应用中经常被忽视，例如网络挖掘 (Luo & Orabona, 2010) 和自动图像标注 (Chen et al., 2018)。这引起了部分标签学习 (PLL) 的重要性 (Hüllermeier & Beringer, 2006; Cour et al., 2011)，其中每个训练示例都配备了一组候选标签而不是确切的真实标签。这与必须选择一个标签作为“黄金”的受监督对应物形成鲜明对比。可以说，PLL 问题在各种情况下被认为更常见和实用，因为它的注释成本相对较低。

<img src="asset/fig1.png" alt="fig1" style="zoom:50%;" />

尽管有承诺，但 PLL 的核心挑战是标签消歧，即从候选标签集中识别真实标签。现有方法通常需要良好的特征表示（Liu & Dietterich, 2012; Zhang et al., 2016; Lyu et al., 2021），并且在特征空间中更接近的数据点更有可能共享的假设下运行相同的真实标签。然而，对表示的依赖导致了一个非同寻常的困境——固有的标签不确定性可能会在表示学习过程中不受欢迎地表现出来——其质量反过来可能会阻碍有效的标签消歧。迄今为止，很少有人努力解决这个问题。

本文通过在一个连贯和协同的框架中调和两个高度相关的问题（表示学习和标签消歧）之间的内在张力来弥合差距。我们的框架，具有对比标签消歧的部分标签学习（称为 PiCO），为来自相同类的示例生成紧密对齐的表示，并促进标签消歧。具体来说，PiCO 封装了两个关键组件。首先，我们利用对比学习 (CL) (Khosla et al., 2020) 来进行部分标签学习，这在以前的 PLL 文献中是未探索的。为了减轻构建正对的关键挑战，我们使用分类器的输出并生成伪正对进行对比比较（第 3.1 节）。其次，基于学习到的嵌入，我们提出了一种新颖的基于原型的标签消歧策略（第 3.2 节）。我们方法的关键是，我们基于最接近的类原型逐步更新分类的伪目标。通过交替上述两个步骤，PiCO 收敛到具有高度可区分表示的解决方案，以实现准确分类。根据经验，PiCO 在三个基准数据集上建立了最先进的性能，显着优于基线（第 4 节），并获得了与完全监督学习相媲美的结果。

从理论上讲，我们证明了我们的对比表示学习和基于原型的标签消歧是互利的，并且可以从期望最大化（EM）算法的角度进行严格解释（第 5 节）。首先，细化的伪标签通过准确地选择伪正样本来改进对比学习。这可以类似于 E-step，我们利用分类器的输出将每个数据示例分配给一个特定于标签的集群。其次，更好的对比性能反过来提高了表示的质量，从而提高了标签消歧的有效性。这可以从 M 步的角度来推断，其中对比损失通过聚类相似的数据示例来部分最大化似然性。最后，训练数据将被映射到单位超球面上的混合 von Mises-Fisher 分布，这有助于通过使用特定于组件的标签来消除标签歧义。我们的主要贡献总结如下：

1（方法）。 据我们所知，我们的论文率先探索了部分标签学习的对比学习，并提出了一个名为 PiCO 的新框架。 作为我们算法的一个组成部分，我们还引入了一种新的基于原型的标签消歧机制，利用了对比学习的嵌入。
2（实验）。 根据经验，我们提出的 PiCO 框架在三个 PLL 任务上建立了最先进的性能。 此外，我们首次尝试在细粒度分类数据集上进行实验，与 CUB-200 数据集的最佳基线相比，分类性能提高了 9.61%。
3（理论）。 我们从期望最大化的角度理论上解释了我们的框架。 我们的推导也可推广到其他 CL 方法，并显示 CL (Wang & Isola, 2020) 中的对齐属性在数学上等于基于中心的聚类算法中的 M 步。

## 2 Background

用 $\mathcal X$ 表示输入所在的特征空间，$\mathcal Y=\{1,2,...,C\}$ 表示输出所在标签空间。PLL 的训练数据集 $\mathcal D=\{(x_i,Y_i)\}^n_{i=1}$，其中 $x_i\in\mathcal X$，而集合 $Y_i\subset \mathcal Y$。PLL 的一个基础假设是：每个样本的 ground-truth label $y_i$ 必然包含于它的候选集 $Y_i$ 中。

作者认为 PLL 的关键挑战在于从候选集中找出正确的标签，所以构造了如下损失函数：

<img src="asset/eq1.png" alt="eq1" style="zoom:50%;" />

在训练过程中，作者给每一张图片 $x_i$ 分配一个正规化的向量 $s_i\in[0,1]^C$，用于表示一个样本属于各个类别的可能性，所以也称其为 pseudo target。在 $s_i$ 的基础上构造 CE loss。

在训练过程中 $s_i$ 会不断更新。理想情况下，$s_i$ 中正确标签对应的值应该越来越大。

## 3 Method

### 3.1 Contrastive Representation Learning for PLL

标签空间中的不确定性为学习表示设置了一个独特的障碍。在 PiCO 中，作者将 eq1 中的 CE 损失与一个对比损失项结合起来，有助于在嵌入空间中产生聚类效果。虽然在最近的文献中已经对对比学习进行了广泛的研究，但它在 PLL 领域仍未得到开发。

主要挑战在于正样本集的构建。在传统的监督 CL 框架中，可以根据真实标签轻松绘制正样本对。然而，这在 PLL 中并不简单。

**Training Objective**

在这篇论文的时代，对比学习最常见的模式如下。给定一个样本 $(x,Y)$，我们通过随机数据增强产生两个新 view，query view 和 key view，分别送入 query network $g(\cdot)$ 和 key network $g'(\cdot)$，生成的结果经过  L2-normalized 得到最终的 embedding $q=g(Aug_q(x))$ 和 $k=g'(Aug_k(x))$。

在结构上，query network 和 key network 继承分类器的卷积块，后接 prediction head（也称 projection head，大概是一个 MLP）。在参数上，key network 使用 query network 的动量更新。

生成的 embedding 中的 k 保存在一个队列中。在训练过程中最新生成的 k 会替代掉队列中最老的 k。而 k 又是由动量更新的 key network 生成的，这样就可以尽量维持队列中的 embedding 的一致性，并且尽量多地保存 embedding。

最终的 contrastive embedding pool 如下：

<img src="asset/eq2.png" alt="eq2" style="zoom:50%;" />

其中 $B_q$ 和 $B_k$ 是当前 mini-batch 生成的 qk embedding。对于一个样本 $x$，它的对比损失就是它的 q embedding 和 pool A 中其他的 embedding 的对比损失：

<img src="asset/eq3.png" alt="eq3" style="zoom:50%;" />

其中，$P(x)$ 是正样本集，$A(x) = \{A-\{q\}\}$ ，$q=g(Aug_q(x))$。

```
对比损失中分子部分可以理解为一个样本的 embedding 和它的正样本的 embedding 的相似程度，分母则是该样本和所有其他样本的 embedding 的相似程度。实际上，对比学习中的正样本只有这个样本它自己，因为代理任务是 instance discrimination。想要对比损失小，就要自己的 q 和 自己的 k 尽量相似（点积大）而和其他样本的 k 尽量不同。
在对比学习的发展过程中有三个要素被证明真正有用：projection head，尽量多的负样本，样本 embedding 一致性高。这也是 MoCo 成功的原因。
```

**Positive Set Selection**

在半监督对比学习中，一个样本的正样本是这个样本自身，负样本是其他所有样本。而在有监督学习中，已经有研究表明，如果把同类别的所有样本都作为该样本的正样本，其他非同类别的样本作为负样本，则有助于有监督学习。

在这个结论下，PLL 就有必要生成更“准确”的正样本集，以提高对比学习的效果。作者使用的方法是把模型对样本的预测当成这个样本的类别，正样本集就是预测类别相同的样本。具体来说，一个样本 $x$ 的预测标签 predicted label $\tilde y = \arg\max_{j\in Y}f^j(Aug_q(x))$，则正样本集按如下规则选出：

<img src="asset/eq4.png" alt="eq4" style="zoom:50%;" />

其中 $\tilde y '$ 表示样本 $k'$ 的 predicted label。从样本 $x$ 的 contrastive embedding pool 中选出那些 predicted label 和自己一样的样本，组成正样本集。这种选择方法还被作者证明是理论上合理的。

最终总损失由 eq1 的分类损失和 eq3 的对比损失组成：

<img src="asset/eq5.png" alt="eq5" style="zoom:50%;" />

### 3.2 Prototype-based Label Disambiguation

正如我们所提到的（稍后在第 5 节中从理论上证明），对比损失在嵌入空间中产生了聚类效应。 作为一种协作算法，我们介绍了我们新颖的基于原型的标签消歧策略。 重要的是，我们保留了一个原型嵌入向量 μc 对应于每个类 c ∈ {1, 2, ..., C }，它可以被视为一组代表性嵌入向量。 明确地说，伪目标分配的一个简单版本是找到当前嵌入向量的最近原型。 值得注意的是，这个原语类似于聚类步骤。 我们还通过使用移动平均样式公式来软化这个硬标签分配版本。 为此，我们可以直观地假设，原型的使用与对比项（第 3.1 节）带来的嵌入空间中的聚类效应建立了联系。 我们在第 5 节中提供了更严格的理由。

**Pseudo Target Updating**

<img src="asset/eq6.png" alt="eq6" style="zoom:50%;" />

**Prototype Updating**

更新原型嵌入的最规范方法是在每次训练迭代中计算它。 然而，这会产生大量的计算量，进而导致难以忍受的训练延迟。 因此，我们以移动平均样式类似地更新类条件原型向量：

<img src="asset/eq7.png" alt="eq7" style="zoom:50%;" />

其中 c 类的动量原型 μc 由归一化查询嵌入 q 的移动平均值定义，其预测类符合 c。 γ 是一个可调的超参数。

### 3.3 Synergy Between Contrastive Learning and Label Disambiguation

虽然看起来彼此分离，但 PiCO 的两个关键组件以协作的方式工作。 首先，由于对比项在嵌入空间中有利地表现出聚类效果，标签消歧模块通过设置更精确的原型进一步利用。 其次，一组经过完善的标签消歧结果可能反过来对作为对比学习阶段关键部分的正集构造进行回报。 当两个组件表现令人满意时，整个训练过程就会收敛。 在第 5 节中，我们进一步严格地将 PiCO 与经典的 EM 风格聚类算法相似。我们的实验，特别是第 4.3 节中显示的消融研究，进一步证明了两个组件之间协同作用的相互依赖性。 我们完整算法的伪代码如附录 C 所示。



























